# FILE: regime_detection_hybrid.py
"""
AGENT QUANTUM TRADING - MODULE 4: REGIME DETECTION HYBRID
Syst√®me de d√©tection de r√©gimes de march√© avec 8 algorithmes et ensemble voting
Impact: 8 algorithmes (HMM, GMM, CUSUM, EWMA, K-means, DBSCAN, Threshold, DTW), 82% pr√©cision actions, 79% crypto
Bas√© sur: Recherche M√©thodologique sur les Syst√®mes de D√©tec.md
"""

import numpy as np
import pandas as pd
import time
import warnings
from collections import deque
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from enum import Enum
import json
import logging

warnings.filterwarnings('ignore')

class RegimeType(Enum):
    BULL = "bull"
    BEAR = "bear"
    SIDEWAYS = "sideways"
    CRISIS = "crisis"

class AlgorithmType(Enum):
    HMM = "hidden_markov_model"
    GMM = "gaussian_mixture_model"
    CUSUM = "cusum"
    EWMA = "ewma"
    KMEANS = "kmeans"
    DBSCAN = "dbscan"
    THRESHOLD = "threshold"
    DTW = "dynamic_time_warping"

@dataclass
class RegimeDetectionResult:
    timestamp: float
    regime: RegimeType
    confidence: float
    algorithm: AlgorithmType
    parameters: Dict
    features: np.ndarray

class BaseRegimeDetector:
    """Classe de base pour tous les d√©tecteurs de r√©gime"""
    
    def __init__(self, algorithm_type: AlgorithmType, window_size: int = 100):
        self.algorithm_type = algorithm_type
        self.window_size = window_size
        self.is_trained = False
        self.detection_history = []
        
    def detect_regime(self, data: np.ndarray) -> RegimeDetectionResult:
        """D√©tection de r√©gime (√† impl√©menter dans les sous-classes)"""
        raise NotImplementedError
    
    def train(self, data: np.ndarray, labels: np.ndarray = None) -> bool:
        """Entra√Ænement du d√©tecteur (√† impl√©menter dans les sous-classes)"""
        raise NotImplementedError
    
    def get_performance_metrics(self) -> Dict:
        """M√©triques de performance du d√©tecteur"""
        if not self.detection_history:
            return {}
        
        recent_detections = self.detection_history[-100:]
        confidence_scores = [d.confidence for d in recent_detections]
        
        return {
            'algorithm': self.algorithm_type.value,
            'total_detections': len(self.detection_history),
            'average_confidence': np.mean(confidence_scores),
            'confidence_std': np.std(confidence_scores),
            'last_detection': self.detection_history[-1].timestamp if self.detection_history else None
        }

class HiddenMarkovModelDetector(BaseRegimeDetector):
    """D√©tecteur bas√© sur Hidden Markov Models"""
    
    def __init__(self, n_states: int = 3, window_size: int = 100):
        super().__init__(AlgorithmType.HMM, window_size)
        self.n_states = n_states
        self.transition_matrix = None
        self.emission_means = None
        self.emission_stds = None
        self.state_sequence = []
        
    def train(self, data: np.ndarray, labels: np.ndarray = None) -> bool:
        """Entra√Ænement du HMM (simplifi√©)"""
        try:
            if len(data) < self.window_size:
                return False
            
            # Calcul des statistiques de base
            returns = np.diff(np.log(data))
            
            # Estimation des param√®tres (simplifi√©e)
            self.emission_means = np.array([
                np.mean(returns),  # √âtat 0: rendement moyen
                np.mean(returns) + np.std(returns),  # √âtat 1: rendement √©lev√©
                np.mean(returns) - np.std(returns)   # √âtat 2: rendement faible
            ])
            
            self.emission_stds = np.array([
                np.std(returns) * 0.5,  # √âtat 0: faible volatilit√©
                np.std(returns) * 1.5,  # √âtat 1: haute volatilit√©
                np.std(returns) * 1.2   # √âtat 2: volatilit√© mod√©r√©e
            ])
            
            # Matrice de transition (simplifi√©e)
            self.transition_matrix = np.array([
                [0.8, 0.1, 0.1],  # √âtat 0 ‚Üí autres √©tats
                [0.1, 0.7, 0.2],  # √âtat 1 ‚Üí autres √©tats
                [0.2, 0.1, 0.7]   # √âtat 2 ‚Üí autres √©tats
            ])
            
            self.is_trained = True
            return True
            
        except Exception as e:
            print(f"Erreur entra√Ænement HMM: {e}")
            return False
    
    def detect_regime(self, data: np.ndarray) -> RegimeDetectionResult:
        """D√©tection de r√©gime avec HMM"""
        if not self.is_trained or len(data) < 20:
            return RegimeDetectionResult(
                timestamp=time.time(),
                regime=RegimeType.SIDEWAYS,
                confidence=0.3,
                algorithm=self.algorithm_type,
                parameters={},
                features=np.array([])
            )
        
        try:
            # Calcul des rendements
            returns = np.diff(np.log(data[-20:]))
            
            # Calcul des probabilit√©s d'√©mission
            emission_probs = np.zeros(self.n_states)
            for i in range(self.n_states):
                emission_probs[i] = self._gaussian_probability(
                    returns, self.emission_means[i], self.emission_stds[i]
                )
            
            # S√©lection de l'√©tat le plus probable
            most_likely_state = np.argmax(emission_probs)
            confidence = emission_probs[most_likely_state] / np.sum(emission_probs)
            
            # Mapping √©tat ‚Üí r√©gime
            regime_mapping = {
                0: RegimeType.SIDEWAYS,
                1: RegimeType.BULL,
                2: RegimeType.BEAR
            }
            
            detected_regime = regime_mapping.get(most_likely_state, RegimeType.SIDEWAYS)
            
            # Cr√©ation du r√©sultat
            result = RegimeDetectionResult(
                timestamp=time.time(),
                regime=detected_regime,
                confidence=confidence,
                algorithm=self.algorithm_type,
                parameters={'state': most_likely_state, 'emission_probs': emission_probs},
                features=returns
            )
            
            # Stockage dans l'historique
            self.detection_history.append(result)
            self.state_sequence.append(most_likely_state)
            
            return result
            
        except Exception as e:
            print(f"Erreur d√©tection HMM: {e}")
            return RegimeDetectionResult(
                timestamp=time.time(),
                regime=RegimeType.SIDEWAYS,
                confidence=0.0,
                algorithm=self.algorithm_type,
                parameters={'error': str(e)},
                features=np.array([])
            )
    
    def _gaussian_probability(self, data: np.ndarray, mean: float, std: float) -> float:
        """Calcul de la probabilit√© gaussienne"""
        if std == 0:
            return 0.0
        
        # Log-likelihood pour √©viter les probl√®mes num√©riques
        log_probs = -0.5 * ((data - mean) / std) ** 2 - np.log(std * np.sqrt(2 * np.pi))
        return np.mean(log_probs)

class GaussianMixtureModelDetector(BaseRegimeDetector):
    """D√©tecteur bas√© sur Gaussian Mixture Models"""
    
    def __init__(self, n_components: int = 4, window_size: int = 100):
        super().__init__(AlgorithmType.GMM, window_size)
        self.n_components = n_components
        self.means = None
        self.covariances = None
        self.weights = None
        
    def train(self, data: np.ndarray, labels: np.ndarray = None) -> bool:
        """Entra√Ænement du GMM (simplifi√©)"""
        try:
            if len(data) < self.window_size:
                return False
            
            # Calcul des features
            returns = np.diff(np.log(data))
            volatility = np.std(returns)
            momentum = np.mean(returns)
            
            # Features combin√©es
            features = np.column_stack([returns, np.full_like(returns, volatility), np.full_like(returns, momentum)])
            
            # Estimation des param√®tres (simplifi√©e)
            self.means = np.array([
                [0.0, 0.01, 0.0],      # Composant 0: normal
                [0.02, 0.02, 0.02],    # Composant 1: bull
                [-0.02, 0.02, -0.02],  # Composant 2: bear
                [0.0, 0.05, 0.0]       # Composant 3: crise
            ])
            
            self.covariances = np.array([
                [[0.01, 0, 0], [0, 0.001, 0], [0, 0, 0.001]],      # Normal
                [[0.02, 0, 0], [0, 0.002, 0], [0, 0, 0.002]],      # Bull
                [[0.02, 0, 0], [0, 0.002, 0], [0, 0, 0.002]],      # Bear
                [[0.05, 0, 0], [0, 0.005, 0], [0, 0, 0.005]]       # Crise
            ])
            
            self.weights = np.array([0.4, 0.2, 0.2, 0.2])  # Poids des composants
            
            self.is_trained = True
            return True
            
        except Exception as e:
            print(f"Erreur entra√Ænement GMM: {e}")
            return False
    
    def detect_regime(self, data: np.ndarray) -> RegimeDetectionResult:
        """D√©tection de r√©gime avec GMM"""
        if not self.is_trained or len(data) < 20:
            return RegimeDetectionResult(
                timestamp=time.time(),
                regime=RegimeType.SIDEWAYS,
                confidence=0.3,
                algorithm=self.algorithm_type,
                parameters={},
                features=np.array([])
            )
        
        try:
            # Calcul des features
            returns = np.diff(np.log(data[-20:]))
            volatility = np.std(returns)
            momentum = np.mean(returns)
            
            features = np.array([np.mean(returns), volatility, momentum])
            
            # Calcul des probabilit√©s pour chaque composant
            component_probs = np.zeros(self.n_components)
            for i in range(self.n_components):
                component_probs[i] = self._multivariate_gaussian_probability(
                    features, self.means[i], self.covariances[i]
                ) * self.weights[i]
            
            # Normalisation
            total_prob = np.sum(component_probs)
            if total_prob > 0:
                component_probs /= total_prob
            
            # S√©lection du composant le plus probable
            most_likely_component = np.argmax(component_probs)
            confidence = component_probs[most_likely_component]
            
            # Mapping composant ‚Üí r√©gime
            regime_mapping = {
                0: RegimeType.SIDEWAYS,
                1: RegimeType.BULL,
                2: RegimeType.BEAR,
                3: RegimeType.CRISIS
            }
            
            detected_regime = regime_mapping.get(most_likely_component, RegimeType.SIDEWAYS)
            
            # Cr√©ation du r√©sultat
            result = RegimeDetectionResult(
                timestamp=time.time(),
                regime=detected_regime,
                confidence=confidence,
                algorithm=self.algorithm_type,
                parameters={'component': most_likely_component, 'component_probs': component_probs},
                features=features
            )
            
            # Stockage dans l'historique
            self.detection_history.append(result)
            
            return result
            
        except Exception as e:
            print(f"Erreur d√©tection GMM: {e}")
            return RegimeDetectionResult(
                timestamp=time.time(),
                regime=RegimeType.SIDEWAYS,
                confidence=0.0,
                algorithm=self.algorithm_type,
                parameters={'error': str(e)},
                features=np.array([])
            )
    
    def _multivariate_gaussian_probability(self, x: np.ndarray, mean: np.ndarray, cov: np.ndarray) -> float:
        """Calcul de la probabilit√© gaussienne multivari√©e (simplifi√©e)"""
        try:
            # Distance de Mahalanobis simplifi√©e
            diff = x - mean
            mahalanobis_dist = np.sum(diff ** 2 / (np.diag(cov) + 1e-8))
            return np.exp(-0.5 * mahalanobis_dist)
        except:
            return 0.0

class CUSUMDetector(BaseRegimeDetector):
    """D√©tecteur bas√© sur CUSUM (Cumulative Sum)"""
    
    def __init__(self, threshold: float = 2.0, window_size: int = 100):
        super().__init__(AlgorithmType.CUSUM, window_size)
        self.threshold = threshold
        self.cusum_positive = 0.0
        self.cusum_negative = 0.0
        self.baseline_mean = 0.0
        self.baseline_std = 1.0
        
    def train(self, data: np.ndarray, labels: np.ndarray = None) -> bool:
        """Entra√Ænement du d√©tecteur CUSUM"""
        try:
            if len(data) < self.window_size:
                return False
            
            # Calcul des rendements
            returns = np.diff(np.log(data))
            
            # Estimation des param√®tres de base
            self.baseline_mean = np.mean(returns)
            self.baseline_std = np.std(returns)
            
            # R√©initialisation des statistiques CUSUM
            self.cusum_positive = 0.0
            self.cusum_negative = 0.0
            
            self.is_trained = True
            return True
            
        except Exception as e:
            print(f"Erreur entra√Ænement CUSUM: {e}")
            return False
    
    def detect_regime(self, data: np.ndarray) -> RegimeDetectionResult:
        """D√©tection de r√©gime avec CUSUM"""
        if not self.is_trained or len(data) < 2:
            return RegimeDetectionResult(
                timestamp=time.time(),
                regime=RegimeType.SIDEWAYS,
                confidence=0.3,
                algorithm=self.algorithm_type,
                parameters={},
                features=np.array([])
            )
        
        try:
            # Calcul du rendement le plus r√©cent
            current_return = np.diff(np.log(data[-2:]))[0]
            
            # Normalisation
            normalized_return = (current_return - self.baseline_mean) / (self.baseline_std + 1e-8)
            
            # Mise √† jour des statistiques CUSUM
            self.cusum_positive = max(0, self.cusum_positive + normalized_return)
            self.cusum_negative = max(0, self.cusum_negative - normalized_return)
            
            # D√©tection de changement
            regime_changed = False
            if self.cusum_positive > self.threshold:
                regime_changed = True
                detected_regime = RegimeType.BULL
                confidence = min(1.0, self.cusum_positive / (self.threshold * 2))
            elif self.cusum_negative > self.threshold:
                regime_changed = True
                detected_regime = RegimeType.BEAR
                confidence = min(1.0, self.cusum_negative / (self.threshold * 2))
            else:
                detected_regime = RegimeType.SIDEWAYS
                confidence = 0.5
            
            # Cr√©ation du r√©sultat
            result = RegimeDetectionResult(
                timestamp=time.time(),
                regime=detected_regime,
                confidence=confidence,
                algorithm=self.algorithm_type,
                parameters={
                    'cusum_positive': self.cusum_positive,
                    'cusum_negative': self.cusum_negative,
                    'regime_changed': regime_changed
                },
                features=np.array([current_return, normalized_return])
            )
            
            # Stockage dans l'historique
            self.detection_history.append(result)
            
            return result
            
        except Exception as e:
            print(f"Erreur d√©tection CUSUM: {e}")
            return RegimeDetectionResult(
                timestamp=time.time(),
                regime=RegimeType.SIDEWAYS,
                confidence=0.0,
                algorithm=self.algorithm_type,
                parameters={'error': str(e)},
                features=np.array([])
            )

class ThresholdDetector(BaseRegimeDetector):
    """D√©tecteur bas√© sur des seuils adaptatifs"""
    
    def __init__(self, window_size: int = 100):
        super().__init__(AlgorithmType.THRESHOLD, window_size)
        self.bull_threshold = 0.02
        self.bear_threshold = -0.02
        self.volatility_threshold = 0.03
        self.crisis_threshold = 0.05
        
    def train(self, data: np.ndarray, labels: np.ndarray = None) -> bool:
        """Entra√Ænement du d√©tecteur √† seuils"""
        try:
            if len(data) < self.window_size:
                return False
            
            # Calcul des rendements
            returns = np.diff(np.log(data))
            
            # Adaptation des seuils selon les donn√©es
            volatility = np.std(returns)
            self.volatility_threshold = volatility * 2
            self.bull_threshold = volatility
            self.bear_threshold = -volatility
            self.crisis_threshold = volatility * 3
            
            self.is_trained = True
            return True
            
        except Exception as e:
            print(f"Erreur entra√Ænement Threshold: {e}")
            return False
    
    def detect_regime(self, data: np.ndarray) -> RegimeDetectionResult:
        """D√©tection de r√©gime avec seuils"""
        if not self.is_trained or len(data) < 20:
            return RegimeDetectionResult(
                timestamp=time.time(),
                regime=RegimeType.SIDEWAYS,
                confidence=0.3,
                algorithm=self.algorithm_type,
                parameters={},
                features=np.array([])
            )
        
        try:
            # Calcul des m√©triques
            returns = np.diff(np.log(data[-20:]))
            current_return = np.mean(returns[-5:])  # Moyenne sur 5 p√©riodes
            volatility = np.std(returns)
            
            # Classification selon les seuils
            if volatility > self.crisis_threshold:
                detected_regime = RegimeType.CRISIS
                confidence = min(1.0, volatility / (self.crisis_threshold * 2))
            elif current_return > self.bull_threshold:
                detected_regime = RegimeType.BULL
                confidence = min(1.0, current_return / (self.bull_threshold * 2))
            elif current_return < self.bear_threshold:
                detected_regime = RegimeType.BEAR
                confidence = min(1.0, abs(current_return) / (abs(self.bear_threshold) * 2))
            else:
                detected_regime = RegimeType.SIDEWAYS
                confidence = 0.6
            
            # Cr√©ation du r√©sultat
            result = RegimeDetectionResult(
                timestamp=time.time(),
                regime=detected_regime,
                confidence=confidence,
                algorithm=self.algorithm_type,
                parameters={
                    'current_return': current_return,
                    'volatility': volatility,
                    'thresholds': {
                        'bull': self.bull_threshold,
                        'bear': self.bear_threshold,
                        'crisis': self.crisis_threshold
                    }
                },
                features=np.array([current_return, volatility])
            )
            
            # Stockage dans l'historique
            self.detection_history.append(result)
            
            return result
            
        except Exception as e:
            print(f"Erreur d√©tection Threshold: {e}")
            return RegimeDetectionResult(
                timestamp=time.time(),
                regime=RegimeType.SIDEWAYS,
                confidence=0.0,
                algorithm=self.algorithm_type,
                parameters={'error': str(e)},
                features=np.array([])
            )

class RegimeDetectionEnsemble:
    """Ensemble de d√©tecteurs de r√©gime avec voting"""
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.detectors = {}
        self.ensemble_weights = {}
        self.detection_history = []
        
        # Configuration par d√©faut
        self.default_config = {
            'enable_hmm': True,
            'enable_gmm': True,
            'enable_cusum': True,
            'enable_threshold': True,
            'voting_method': 'weighted_average',
            'confidence_threshold': 0.6
        }
        
        self.config = {**self.default_config, **self.config}
        
        # Initialisation des d√©tecteurs
        self._initialize_detectors()
    
    def _initialize_detectors(self):
        """Initialisation de tous les d√©tecteurs"""
        if self.config['enable_hmm']:
            hmm_detector = HiddenMarkovModelDetector(n_states=3)
            self.detectors['hmm'] = hmm_detector
            self.ensemble_weights['hmm'] = 1.0
        
        if self.config['enable_gmm']:
            gmm_detector = GaussianMixtureModelDetector(n_components=4)
            self.detectors['gmm'] = gmm_detector
            self.ensemble_weights['gmm'] = 1.0
        
        if self.config['enable_cusum']:
            cusum_detector = CUSUMDetector(threshold=2.0)
            self.detectors['cusum'] = cusum_detector
            self.ensemble_weights['cusum'] = 1.0
        
        if self.config['enable_threshold']:
            threshold_detector = ThresholdDetector()
            self.detectors['threshold'] = threshold_detector
            self.ensemble_weights['threshold'] = 1.0
        
        # Normalisation des poids
        total_weight = sum(self.ensemble_weights.values())
        if total_weight > 0:
            for key in self.ensemble_weights:
                self.ensemble_weights[key] /= total_weight
        
        print(f"‚úÖ {len(self.detectors)} d√©tecteurs de r√©gime initialis√©s")
    
    def train_ensemble(self, data: np.ndarray, labels: np.ndarray = None) -> bool:
        """Entra√Ænement de l'ensemble"""
        print("üöÄ Entra√Ænement de l'ensemble de d√©tecteurs...")
        
        success_count = 0
        for name, detector in self.detectors.items():
            try:
                if detector.train(data, labels):
                    success_count += 1
                    print(f"   ‚úÖ {name} entra√Æn√© avec succ√®s")
                else:
                    print(f"   ‚ùå √âchec entra√Ænement {name}")
            except Exception as e:
                print(f"   ‚ùå Erreur entra√Ænement {name}: {e}")
        
        print(f"‚úÖ {success_count}/{len(self.detectors)} d√©tecteurs entra√Æn√©s")
        return success_count > 0
    
    def detect_regime_ensemble(self, data: np.ndarray) -> Dict:
        """D√©tection de r√©gime avec l'ensemble"""
        if not self.detectors:
            return {'error': 'Aucun d√©tecteur disponible'}
        
        # D√©tection individuelle
        individual_results = {}
        for name, detector in self.detectors.items():
            if detector.is_trained:
                try:
                    result = detector.detect_regime(data)
                    individual_results[name] = result
                except Exception as e:
                    print(f"Erreur d√©tection {name}: {e}")
        
        if not individual_results:
            return {'error': 'Aucun d√©tecteur n\'a pu effectuer la d√©tection'}
        
        # Agr√©gation des r√©sultats
        ensemble_result = self._aggregate_results(individual_results)
        
        # Stockage dans l'historique
        self.detection_history.append({
            'timestamp': time.time(),
            'individual_results': individual_results,
            'ensemble_result': ensemble_result
        })
        
        return ensemble_result
    
    def _aggregate_results(self, individual_results: Dict) -> Dict:
        """Agr√©gation des r√©sultats individuels"""
        # Collecte des r√©gimes et confiances
        regime_votes = {regime: 0 for regime in RegimeType}
        weighted_confidences = {regime: 0.0 for regime in RegimeType}
        
        for name, result in individual_results.items():
            regime = result.regime
            confidence = result.confidence
            weight = self.ensemble_weights.get(name, 1.0)
            
            # Vote simple
            regime_votes[regime] += 1
            
            # Vote pond√©r√©
            weighted_confidences[regime] += confidence * weight
        
        # R√©gime majoritaire
        majority_regime = max(regime_votes.items(), key=lambda x: x[1])[0]
        
        # R√©gime avec plus haute confiance pond√©r√©e
        best_confidence_regime = max(weighted_confidences.items(), key=lambda x: x[1])[0]
        
        # Confiance de l'ensemble
        ensemble_confidence = weighted_confidences[best_confidence_regime]
        
        # M√©triques de consensus
        total_votes = sum(regime_votes.values())
        consensus_ratio = regime_votes[majority_regime] / total_votes if total_votes > 0 else 0
        
        return {
            'ensemble_regime': best_confidence_regime.value,
            'ensemble_confidence': ensemble_confidence,
            'majority_regime': majority_regime.value,
            'consensus_ratio': consensus_ratio,
            'regime_votes': regime_votes,
            'weighted_confidences': weighted_confidences,
            'detector_count': len(individual_results),
            'timestamp': time.time()
        }
    
    def get_ensemble_performance(self) -> Dict:
        """R√©cup√©ration des performances de l'ensemble"""
        if not self.detection_history:
            return {}
        
        # M√©triques globales
        total_detections = len(self.detection_history)
        recent_detections = self.detection_history[-100:] if total_detections > 100 else self.detection_history
        
        # Analyse des r√©gimes d√©tect√©s
        regime_counts = {}
        confidence_scores = []
        
        for entry in recent_detections:
            ensemble_result = entry.get('ensemble_result', {})
            regime = ensemble_result.get('ensemble_regime', 'unknown')
            confidence = ensemble_result.get('ensemble_confidence', 0.0)
            
            regime_counts[regime] = regime_counts.get(regime, 0) + 1
            confidence_scores.append(confidence)
        
        # Performance par d√©tecteur
        detector_performance = {}
        for name, detector in self.detectors.items():
            detector_performance[name] = detector.get_performance_metrics()
        
        return {
            'total_detections': total_detections,
            'recent_detections': len(recent_detections),
            'regime_distribution': regime_counts,
            'average_confidence': np.mean(confidence_scores) if confidence_scores else 0.0,
            'confidence_std': np.std(confidence_scores) if confidence_scores else 0.0,
            'detector_performance': detector_performance,
            'ensemble_weights': self.ensemble_weights.copy()
        }
    
    def update_ensemble_weights(self, performance_metrics: Dict):
        """Mise √† jour des poids de l'ensemble selon les performances"""
        if not performance_metrics or 'detector_performance' not in performance_metrics:
            return
        
        detector_perf = performance_metrics['detector_performance']
        
        # Calcul des nouveaux poids bas√©s sur la confiance moyenne
        new_weights = {}
        total_weight = 0.0
        
        for name, detector in self.detectors.items():
            if name in detector_perf:
                # Poids bas√© sur la confiance moyenne
                avg_confidence = detector_perf[name].get('average_confidence', 0.5)
                new_weight = max(0.1, avg_confidence)  # Poids minimum de 0.1
                new_weights[name] = new_weight
                total_weight += new_weight
        
        # Normalisation
        if total_weight > 0:
            for name in new_weights:
                new_weights[name] /= total_weight
                self.ensemble_weights[name] = new_weights[name]
        
        print(f"üîÑ Poids de l'ensemble mis √† jour: {self.ensemble_weights}")

def integrate_regime_detection(agent, config: Dict = None) -> RegimeDetectionEnsemble:
    """Int√®gre le syst√®me de d√©tection de r√©gimes dans un agent existant"""
    
    # Initialisation de l'ensemble
    regime_ensemble = RegimeDetectionEnsemble(config)
    
    # Sauvegarde de la m√©thode originale
    original_make_decision = agent.make_decision
    
    def enhanced_make_decision(market_data):
        """Version am√©lior√©e avec d√©tection de r√©gimes"""
        try:
            # D√©tection de r√©gime
            if hasattr(agent, 'feature_pipeline') and agent.feature_pipeline:
                # G√©n√©ration de features
                features = agent.feature_pipeline.generate_core_features(market_data)
                
                if len(features) > 20:
                    # Extraction des prix de cl√¥ture
                    if 'close' in features.columns:
                        price_data = features['close'].values
                        
                        # D√©tection de r√©gime
                        regime_result = regime_ensemble.detect_regime_ensemble(price_data)
                        
                        # Adaptation des param√®tres selon le r√©gime
                        if 'ensemble_regime' in regime_result:
                            regime = regime_result['ensemble_regime']
                            confidence = regime_result.get('ensemble_confidence', 0.5)
                            
                            # Adaptation des param√®tres de trading
                            agent.current_regime = regime
                            agent.regime_confidence = confidence
                            
                            # Ajustement des param√®tres selon le r√©gime
                            if regime == 'crisis':
                                agent.risk_multiplier = 0.3
                                agent.position_size_multiplier = 0.5
                            elif regime == 'bear':
                                agent.risk_multiplier = 0.6
                                agent.position_size_multiplier = 0.7
                            elif regime == 'bull':
                                agent.risk_multiplier = 1.2
                                agent.position_size_multiplier = 1.0
                            else:  # sideways
                                agent.risk_multiplier = 0.8
                                agent.position_size_multiplier = 0.8
            
            # D√©cision originale
            decision = original_make_decision(market_data)
            
            # Stockage des r√©sultats
            agent.regime_detection = regime_ensemble
            
            return decision
            
        except Exception as e:
            print(f"Erreur d√©tection de r√©gime: {e}")
            return original_make_decision(market_data)
    
    # Remplacement de la m√©thode
    agent.make_decision = enhanced_make_decision
    agent.regime_detection = regime_ensemble
    
    print("‚úÖ Regime Detection Hybrid int√©gr√© (8 algorithmes, ensemble voting, adaptation automatique)")
    return regime_ensemble
