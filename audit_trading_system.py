"""
üîç AUDIT COMPLET DU SYST√àME DE TRADING
Analyse de la rentabilit√© r√©elle et de la capacit√© d'apprentissage
"""

import sys
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('AUDIT')

def run_complete_audit():
    print('='*70)
    print('üîç AUDIT COMPLET DU SYST√àME DE TRADING')
    print('='*70)
    
    # Test 1: V√©rifier le capital initial
    print('\nüìä TEST 1: Configuration du Capital')
    print('-'*40)
    from rl_trading_agent import TradingEnvironment
    
    # Cr√©er environnement avec capital par d√©faut
    test_data = pd.DataFrame({'close': [100], 'rsi': [50], 'macd': [0], 'volume': [1000000]})
    env = TradingEnvironment(test_data)
    print(f'Capital initial actuel: ${env.initial_balance:,.2f}')
    print(f'Balance initiale: ${env.balance:,.2f}')
    
    # Test avec capital de 1000$
    env_1000 = TradingEnvironment(test_data, initial_balance=1000)
    print(f'Test avec capital de 1000$: ${env_1000.initial_balance:,.2f}')
    
    # Test 2: V√©rifier la capacit√© d'apprentissage
    print('\nüß† TEST 2: Capacit√© d\'Apprentissage')
    print('-'*40)
    
    # Cr√©er donn√©es de test avec tendance claire
    dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')
    trend_data = pd.DataFrame({
        'close': 100 + np.arange(len(dates)) * 0.1,  # Tendance haussi√®re
        'rsi': 50 + np.sin(np.arange(len(dates)) * 0.1) * 20,
        'macd': np.sin(np.arange(len(dates)) * 0.05) * 2,
        'volume': np.random.uniform(900000, 1100000, len(dates))
    }, index=dates)
    
    from rl_trading_agent import RLTrader
    
    rl_trader = RLTrader()
    print('Entra√Ænement du mod√®le RL sur donn√©es avec tendance...')
    
    # Entra√Æner sur premi√®re moiti√©
    train_data = trend_data.iloc[:180]
    rl_trader.train_model(train_data, total_timesteps=2000)
    
    # √âvaluer sur deuxi√®me moiti√©
    test_data = trend_data.iloc[180:]
    metrics = rl_trader.evaluate_performance(test_data)
    
    print(f'R√©sultats apr√®s entra√Ænement:')
    print(f'  - Return final: {metrics.get("final_return", 0):.2f}%')
    print(f'  - Win rate: {metrics.get("win_rate", 0):.1%}')
    print(f'  - Nombre de trades: {metrics.get("total_trades", 0)}')
    
    # Test 3: V√©rifier la rentabilit√© r√©elle
    print('\nüí∞ TEST 3: Rentabilit√© R√©elle')
    print('-'*40)
    
    # Simuler trading avec capital de 1000$
    env_real = TradingEnvironment(test_data, initial_balance=1000)
    obs, _ = env_real.reset()
    done = False
    trades_log = []
    
    while not done:
        action, _ = rl_trader.model.predict(obs, deterministic=True)
        obs, reward, done, truncated, info = env_real.step(action)
        
        if 'action' in info:
            trades_log.append(info)
    
    final_balance = env_real.balance
    profit = final_balance - 1000
    roi = (profit / 1000) * 100
    
    print(f'Capital initial: $1,000.00')
    print(f'Balance finale: ${final_balance:.2f}')
    print(f'Profit/Perte: ${profit:.2f}')
    print(f'ROI: {roi:.2f}%')
    
    if len(trades_log) > 0:
        winning_trades = [t for t in trades_log if t.get('profit', 0) > 0]
        print(f'Trades gagnants: {len(winning_trades)}/{len(trades_log)}')
    
    # Test 4: Analyse de la m√©moire et apprentissage continu
    print('\nüîÑ TEST 4: M√©moire et Apprentissage Continu')
    print('-'*40)
    
    # V√©rifier si le mod√®le s'am√©liore avec le temps
    performance_history = []
    
    for epoch in range(3):
        print(f'\n√âpoque {epoch + 1}/3:')
        # G√©n√©rer nouvelles donn√©es
        new_dates = pd.date_range(start=f'2024-0{epoch+1}-01', end=f'2024-0{epoch+1}-30', freq='D')
        new_data = pd.DataFrame({
            'close': 100 + np.random.randn(len(new_dates)) * 2,
            'rsi': 50 + np.random.randn(len(new_dates)) * 10,
            'macd': np.random.randn(len(new_dates)) * 0.5,
            'volume': np.random.uniform(900000, 1100000, len(new_dates))
        }, index=new_dates)
        
        # Continuer l'entra√Ænement
        rl_trader.train_model(new_data, total_timesteps=500)
        
        # √âvaluer performance
        eval_metrics = rl_trader.evaluate_performance(new_data)
        performance_history.append(eval_metrics.get('final_return', 0))
        print(f'  Performance: {eval_metrics.get("final_return", 0):.2f}%')
    
    # V√©rifier am√©lioration
    if len(performance_history) > 1:
        improvement = performance_history[-1] - performance_history[0]
        print(f'\nüìà Am√©lioration sur 3 √©poques: {improvement:.2f}%')
        
        if improvement > 0:
            print('‚úÖ Le mod√®le montre une capacit√© d\'apprentissage positive')
        else:
            print('‚ö†Ô∏è Le mod√®le ne montre pas d\'am√©lioration significative')
    
    # Test 5: Analyse des probl√®mes critiques
    print('\n‚ö†Ô∏è TEST 5: Probl√®mes Critiques Identifi√©s')
    print('-'*40)
    
    issues = []
    
    # V√©rifier le capital
    if env.initial_balance == 100000:
        issues.append('Capital initial trop √©lev√© (100k$) - peu r√©aliste pour tests')
    
    # V√©rifier les donn√©es
    if env.shares == 0 and env.balance == env.initial_balance:
        issues.append('Agent ne fait peut-√™tre pas de trades r√©els')
    
    # V√©rifier la rentabilit√©
    if roi < 0:
        issues.append(f'ROI n√©gatif ({roi:.2f}%) - agent perd de l\'argent')
    elif roi < 5:
        issues.append(f'ROI faible ({roi:.2f}%) - performance insuffisante')
    
    if issues:
        print('Probl√®mes d√©tect√©s:')
        for i, issue in enumerate(issues, 1):
            print(f'  {i}. {issue}')
    else:
        print('‚úÖ Aucun probl√®me critique d√©tect√©')
    
    print('\n' + '='*70)
    print('üìä R√âSUM√â DE L\'AUDIT')
    print('='*70)
    
    summary = {
        'Capital actuel': f'${env.initial_balance:,.0f}',
        'Capital recommand√©': '$1,000',
        'ROI observ√©': f'{roi:.2f}%',
        'Capacit√© d\'apprentissage': '√Ä am√©liorer' if improvement <= 0 else 'Positive',
        'Recommandation': 'N√©cessite int√©gration Memory Decoder'
    }
    
    for key, value in summary.items():
        print(f'{key:.<25} {value}')
    
    print('\n‚úÖ Audit termin√©')
    
    return {
        'current_capital': env.initial_balance,
        'roi': roi,
        'learning_improvement': improvement if 'improvement' in locals() else 0,
        'issues': issues
    }

if __name__ == "__main__":
    results = run_complete_audit()
