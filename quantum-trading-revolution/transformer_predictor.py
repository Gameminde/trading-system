"""
üöÄ TRANSFORMER PREDICTOR - PR√âDICTION DE PRIX AVANC√âE
‚úÖ Mod√®le Transformer basique pour pr√©diction temporelle
üéØ Objectif: +20-30% pr√©cision des signaux trading
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import logging
import math
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [%(name)s] %(message)s')
logger = logging.getLogger("TRANSFORMER_PREDICTOR")

class PositionalEncoding(nn.Module):
    """Encodage positionnel pour le Transformer"""
    
    def __init__(self, d_model: int, max_len: int = 5000):
        super().__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        
        div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                           -(math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe.unsqueeze(0))
        
    def forward(self, x):
        return x + self.pe[:, :x.size(1)]

class TimeSeriesTransformer(nn.Module):
    """Mod√®le Transformer pour s√©ries temporelles"""
    
    def __init__(self, input_dim: int, model_dim: int = 64, num_heads: int = 8, num_layers: int = 3):
        super().__init__()
        
        self.input_projection = nn.Linear(input_dim, model_dim)
        self.positional_encoding = PositionalEncoding(model_dim)
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=model_dim,
            nhead=num_heads,
            dim_feedforward=256,
            dropout=0.1
        )
        
        self.transformer = nn.TransformerEncoder(
            encoder_layer, 
            num_layers=num_layers
        )
        
        self.output_projection = nn.Linear(model_dim, 1)
        
        logger.info(f"ü§ñ Transformer cr√©√©: {input_dim} ‚Üí {model_dim} ‚Üí 1")
        logger.info(f"   T√™tes d'attention: {num_heads}")
        logger.info(f"   Couches: {num_layers}")
    
    def forward(self, x):
        # x shape: (batch_size, seq_len, input_dim)
        x = self.input_projection(x)
        x = self.positional_encoding(x)
        
        # Transformer expects (seq_len, batch_size, model_dim)
        x = x.transpose(0, 1)
        x = self.transformer(x)
        x = x.transpose(0, 1)
        
        # Prendre la derni√®re pr√©diction
        prediction = self.output_projection(x[:, -1, :])
        return prediction

class PriceDataset(Dataset):
    """Dataset pour les donn√©es de prix"""
    
    def __init__(self, X: np.ndarray, y: np.ndarray):
        self.X = torch.FloatTensor(X)
        self.y = torch.FloatTensor(y)
        
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

class PricePredictor:
    """Pr√©dicteur de prix utilisant un Transformer"""
    
    def __init__(self, sequence_length: int = 60):
        self.sequence_length = sequence_length
        self.model = None
        self.scaler = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.feature_names = ['open', 'high', 'low', 'close', 'volume', 'rsi', 'macd']
        
        logger.info(f"üöÄ Price Predictor initialis√©")
        logger.info(f"   S√©quence: {sequence_length} p√©riodes")
        logger.info(f"   Device: {self.device}")
    
    def prepare_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """Pr√©parer donn√©es pour entra√Ænement"""
        logger.info(f"üìä Pr√©paration donn√©es: {len(df)} p√©riodes")
        
        # V√©rifier que toutes les colonnes n√©cessaires sont pr√©sentes
        missing_features = [f for f in self.feature_names if f not in df.columns]
        if missing_features:
            logger.warning(f"‚ö†Ô∏è Colonnes manquantes: {missing_features}")
            # Cr√©er des colonnes par d√©faut
            for feature in missing_features:
                if feature in ['rsi', 'macd']:
                    df[feature] = 50.0  # Valeur neutre
                elif feature == 'volume':
                    df[feature] = 1000000  # Volume par d√©faut
                else:
                    df[feature] = df['close']  # Copier le prix de cl√¥ture
        
        # S√©lectionner les features
        data = df[self.feature_names].values
        
        # Normaliser les donn√©es
        from sklearn.preprocessing import MinMaxScaler
        self.scaler = MinMaxScaler()
        scaled_data = self.scaler.fit_transform(data)
        
        # Cr√©er s√©quences
        X, y = [], []
        for i in range(self.sequence_length, len(scaled_data)):
            X.append(scaled_data[i-self.sequence_length:i])
            y.append(scaled_data[i, 3])  # Prix de cl√¥ture (index 3)
        
        X = np.array(X)
        y = np.array(y)
        
        logger.info(f"‚úÖ Donn√©es pr√©par√©es: X={X.shape}, y={y.shape}")
        return X, y
    
    def train_model(self, df: pd.DataFrame, epochs: int = 100, batch_size: int = 32):
        """Entra√Æner le mod√®le Transformer"""
        logger.info(f"ü§ñ D√©but entra√Ænement Transformer")
        logger.info(f"   √âpoques: {epochs}")
        logger.info(f"   Batch size: {batch_size}")
        
        try:
            # Pr√©parer les donn√©es
            X, y = self.prepare_data(df)
            
            if len(X) == 0:
                logger.error("‚ùå Pas assez de donn√©es pour l'entra√Ænement")
                return False
            
            # Cr√©er le mod√®le
            input_dim = X.shape[2]
            self.model = TimeSeriesTransformer(input_dim).to(self.device)
            
            # Pr√©parer DataLoader
            dataset = PriceDataset(X, y)
            dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
            
            # Entra√Ænement
            optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
            criterion = nn.MSELoss()
            
            self.model.train()
            for epoch in range(epochs):
                total_loss = 0
                for batch_X, batch_y in dataloader:
                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                    
                    optimizer.zero_grad()
                    predictions = self.model(batch_X).squeeze()
                    loss = criterion(predictions, batch_y)
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
                
                if epoch % 20 == 0:
                    avg_loss = total_loss / len(dataloader)
                    logger.info(f"üìà Epoch {epoch}, Loss: {avg_loss:.6f}")
            
            logger.info("‚úÖ Entra√Ænement Transformer termin√© avec succ√®s")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur entra√Ænement: {e}")
            return False
    
    def predict_next_price(self, recent_data: pd.DataFrame) -> Optional[float]:
        """Pr√©dire le prochain prix"""
        if self.model is None:
            logger.warning("‚ö†Ô∏è Mod√®le non entra√Æn√©")
            return None
        
        try:
            # V√©rifier qu'il y a assez de donn√©es
            if len(recent_data) < self.sequence_length:
                logger.warning(f"‚ö†Ô∏è Donn√©es insuffisantes: {len(recent_data)} < {self.sequence_length}")
                return None
            
            # Pr√©parer les donn√©es r√©centes
            data = recent_data[self.feature_names].tail(self.sequence_length).values
            scaled_data = self.scaler.transform(data)
            
            # Pr√©diction
            self.model.eval()
            with torch.no_grad():
                x = torch.FloatTensor(scaled_data).unsqueeze(0).to(self.device)
                prediction = self.model(x).cpu().numpy()[0]
            
            # D√©-normaliser la pr√©diction
            dummy = np.zeros((1, len(self.feature_names)))
            dummy[0, 3] = prediction  # Position du prix de cl√¥ture
            denormalized = self.scaler.inverse_transform(dummy)
            
            predicted_price = denormalized[0, 3]
            logger.info(f"üîÆ Prix pr√©dit: ${predicted_price:.2f}")
            
            return predicted_price
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©diction: {e}")
            return None
    
    def evaluate_model(self, test_df: pd.DataFrame) -> Dict:
        """√âvaluer la performance du mod√®le"""
        if self.model is None:
            return {'error': 'Mod√®le non entra√Æn√©'}
        
        try:
            logger.info("üìä √âvaluation du mod√®le Transformer")
            
            # Pr√©parer donn√©es de test
            X_test, y_test = self.prepare_data(test_df)
            
            if len(X_test) == 0:
                return {'error': 'Donn√©es de test insuffisantes'}
            
            # Pr√©dictions
            self.model.eval()
            predictions = []
            
            with torch.no_grad():
                for i in range(len(X_test)):
                    x = torch.FloatTensor(X_test[i:i+1]).to(self.device)
                    pred = self.model(x).cpu().numpy()[0]
                    predictions.append(pred)
            
            # D√©-normaliser
            dummy = np.zeros((len(predictions), len(self.feature_names)))
            dummy[:, 3] = predictions
            denormalized_preds = self.scaler.inverse_transform(dummy)[:, 3]
            
            # D√©-normaliser les vraies valeurs
            dummy[:, 3] = y_test
            denormalized_actuals = self.scaler.inverse_transform(dummy)[:, 3]
            
            # Calculer m√©triques
            mse = np.mean((denormalized_preds - denormalized_actuals) ** 2)
            mae = np.mean(np.abs(denormalized_preds - denormalized_actuals))
            mape = np.mean(np.abs((denormalized_actuals - denormalized_preds) / denormalized_actuals)) * 100
            
            results = {
                'mse': mse,
                'mae': mae,
                'mape': mape,
                'predictions_count': len(predictions),
                'avg_predicted_price': np.mean(denormalized_preds),
                'avg_actual_price': np.mean(denormalized_actuals)
            }
            
            logger.info(f"üìä MSE: {mse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur √©valuation: {e}")
            return {'error': str(e)}
    
    def save_model(self, filepath: str):
        """Sauvegarder le mod√®le entra√Æn√©"""
        if self.model is None:
            logger.warning("‚ö†Ô∏è Aucun mod√®le √† sauvegarder")
            return False
        
        try:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'scaler': self.scaler,
                'sequence_length': self.sequence_length,
                'feature_names': self.feature_names
            }, filepath)
            logger.info(f"üíæ Mod√®le sauvegard√©: {filepath}")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde: {e}")
            return False
    
    def load_model(self, filepath: str):
        """Charger un mod√®le pr√©-entra√Æn√©"""
        try:
            checkpoint = torch.load(filepath, map_location=self.device)
            
            # Recr√©er le mod√®le
            input_dim = len(checkpoint['feature_names'])
            self.model = TimeSeriesTransformer(input_dim).to(self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            
            # Restaurer les autres param√®tres
            self.scaler = checkpoint['scaler']
            self.sequence_length = checkpoint['sequence_length']
            self.feature_names = checkpoint['feature_names']
            
            logger.info(f"‚úÖ Mod√®le charg√©: {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement: {e}")
            return False

def create_sample_data(n_periods: int = 1000) -> pd.DataFrame:
    """Cr√©er des donn√©es d'exemple pour test"""
    np.random.seed(42)
    
    # Prix simul√©s avec tendance et volatilit√© r√©aliste
    base_price = 100.0
    prices = [base_price]
    
    for i in range(1, n_periods):
        # Tendance + bruit + volatilit√©
        trend = 0.0001 * i  # Tendance l√©g√®rement haussi√®re
        noise = np.random.normal(0, 0.02)  # 2% volatilit√©
        volatility_cluster = 0.01 * np.sin(i / 50)  # Clusters de volatilit√©
        
        new_price = prices[-1] * (1 + trend + noise + volatility_cluster)
        prices.append(max(new_price, 1.0))  # Prix minimum $1
    
    # Cr√©er DataFrame avec OHLCV
    df = pd.DataFrame({
        'open': prices,
        'high': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
        'low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
        'close': prices,
        'volume': np.random.randint(100000, 1000000, n_periods),
        'rsi': np.random.uniform(20, 80, n_periods),
        'macd': np.random.uniform(-2, 2, n_periods)
    })
    
    return df

def main():
    """Test du syst√®me Transformer"""
    print("üöÄ" + "="*80 + "üöÄ")
    print("   üî• TRANSFORMER PREDICTOR - PR√âDICTION DE PRIX AVANC√âE")
    print("="*84)
    print("   ‚úÖ Mod√®le Transformer PyTorch")
    print("   ‚úÖ Encodage positionnel")
    print("   ‚úÖ Multi-head attention")
    print("   üéØ Objectif: +20-30% pr√©cision trading")
    print("üöÄ" + "="*80 + "üöÄ")
    
    # Cr√©er donn√©es d'exemple
    print("\nüìä Cr√©ation donn√©es d'exemple...")
    sample_data = create_sample_data(800)
    print(f"   ‚úÖ {len(sample_data)} p√©riodes cr√©√©es")
    
    # Diviser en train/test
    split_idx = int(len(sample_data) * 0.8)
    train_data = sample_data[:split_idx]
    test_data = sample_data[split_idx:]
    
    print(f"   üìà Entra√Ænement: {len(train_data)} p√©riodes")
    print(f"   üß™ Test: {len(test_data)} p√©riodes")
    
    # Initialiser le pr√©dicteur
    predictor = PricePredictor(sequence_length=60)
    
    # Entra√Æner le mod√®le
    print("\nü§ñ Entra√Ænement du mod√®le Transformer...")
    success = predictor.train_model(train_data, epochs=50, batch_size=16)
    
    if success:
        # √âvaluer le mod√®le
        print("\nüìä √âvaluation du mod√®le...")
        results = predictor.evaluate_model(test_data)
        
        if 'error' not in results:
            print(f"   üìà MSE: {results['mse']:.4f}")
            print(f"   üìä MAE: {results['mae']:.4f}")
            print(f"   üìä MAPE: {results['mape']:.2f}%")
            print(f"   üîÆ Pr√©dictions: {results['predictions_count']}")
        else:
            print(f"   ‚ùå Erreur: {results['error']}")
        
        # Test de pr√©diction
        print("\nüîÆ Test de pr√©diction...")
        recent_data = test_data.tail(100)  # 100 derni√®res p√©riodes
        predicted_price = predictor.predict_next_price(recent_data)
        
        if predicted_price:
            current_price = recent_data['close'].iloc[-1]
            price_change = (predicted_price - current_price) / current_price * 100
            
            print(f"   üí∞ Prix actuel: ${current_price:.2f}")
            print(f"   üîÆ Prix pr√©dit: ${predicted_price:.2f}")
            print(f"   üìà Changement pr√©dit: {price_change:+.2f}%")
            
            # Recommandation
            if price_change > 1:
                recommendation = "BUY"
            elif price_change < -1:
                recommendation = "SELL"
            else:
                recommendation = "HOLD"
            
            print(f"   üéØ Recommandation: {recommendation}")
        
        # Sauvegarder le mod√®le
        print("\nüíæ Sauvegarde du mod√®le...")
        predictor.save_model("transformer_model.pth")
        
    else:
        print("   ‚ùå Entra√Ænement √©chou√©")
    
    print("\n‚úÖ Test Transformer termin√©!")

if __name__ == "__main__":
    main()
