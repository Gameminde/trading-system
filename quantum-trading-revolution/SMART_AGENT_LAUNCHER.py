"""
ğŸš€ SMART AGENT LAUNCHER - CHOIX INTELLIGENT

MISSION: Lancer l'agent optimal selon les donnÃ©es disponibles
OPTIONS: Agent standard vs Agent entraÃ®nÃ© historiquement
RÃ‰SULTAT: Performance maximale basÃ©e sur vraie connaissance du marchÃ©

ğŸ’ L'INTERFACE PARFAITE POUR CHOISIR SON AGENT !
"""

import os
import sys
import json
from datetime import datetime
import logging

# Configuration logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SMART_LAUNCHER")

class SmartAgentLauncher:
    """Lanceur intelligent pour choisir le meilleur agent"""
    
    def __init__(self):
        self.models_dir = "models/trained"
        self.has_trained_agent = False
        self.training_info = None
        
        self.check_trained_models()
    
    def check_trained_models(self):
        """VÃ©rifier si un agent entraÃ®nÃ© existe"""
        
        trained_agent_path = f"{self.models_dir}/trained_agent.pkl"
        training_results_path = f"{self.models_dir}/training_results.json"
        
        if os.path.exists(trained_agent_path) and os.path.exists(training_results_path):
            self.has_trained_agent = True
            
            try:
                with open(training_results_path, 'r') as f:
                    self.training_info = json.load(f)
                    
                logger.info("âœ… Trained agent found")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Error reading training info: {e}")
        else:
            logger.info("ğŸ“Š No trained agent found")
    
    def display_options(self):
        """Afficher les options disponibles"""
        
        print("ğŸš€" + "="*70 + "ğŸš€")
        print("   ğŸ§  SMART AGENT LAUNCHER - CHOISISSEZ VOTRE ARME")
        print("="*74)
        
        print(f"\nğŸ“Š OPTIONS DISPONIBLES :")
        
        # Option 1: Agent Standard
        print(f"\n1ï¸âƒ£ AGENT OPTIMIZED (Standard)")
        print(f"   âš¡ Puissance: 95% modules actifs")
        print(f"   ğŸ§  Intelligence: LLM + MPS + Quantum")
        print(f"   ğŸ“Š DonnÃ©es: Temps rÃ©el uniquement")
        print(f"   ğŸ¯ Performance: OptimisÃ© anti-overtrading")
        print(f"   âœ… Status: Toujours disponible")
        
        # Option 2: Agent EntraÃ®nÃ© (si disponible)
        if self.has_trained_agent:
            print(f"\n2ï¸âƒ£ AGENT TRAINED (Historiquement Intelligent) â­ RECOMMANDÃ‰")
            print(f"   ğŸ“ EntraÃ®nÃ© sur: {self.training_info.get('data_periods', {}).get('crypto_years', 5)} ans crypto + {self.training_info.get('data_periods', {}).get('stocks_years', 5)} ans stocks")
            print(f"   ğŸ“ˆ Patterns appris: {self.training_info.get('patterns_found', 0)} stratÃ©gies gagnantes")
            print(f"   ğŸ” RÃ©gimes identifiÃ©s: {self.training_info.get('regimes_identified', 0)} contextes de marchÃ©")
            print(f"   ğŸ§  Config optimisÃ©e: BasÃ©e sur backtest historique")
            print(f"   ğŸ“… EntraÃ®nÃ© le: {self.training_info.get('training_date', 'N/A')[:10]}")
            print(f"   âœ… Status: PrÃªt pour performance supÃ©rieure")
        else:
            print(f"\n2ï¸âƒ£ AGENT TRAINED (Non disponible)")
            print(f"   âŒ Pas encore entraÃ®nÃ©")
            print(f"   ğŸ“ ExÃ©cutez 'python HISTORICAL_DATA_TRAINER.py' d'abord")
            print(f"   â±ï¸ Temps d'entraÃ®nement: ~10-15 minutes")
            print(f"   ğŸ’¡ Collecte 5-10 ans de donnÃ©es BTC, ETH, TSLA, AAPL")
        
        # Option 3: EntraÃ®nement
        print(f"\n3ï¸âƒ£ ENTRAÃNER NOUVEAU AGENT")
        print(f"   ğŸ“š Collecte donnÃ©es historiques complÃ¨tes")
        print(f"   ğŸ” Analyse patterns gagnants sur 5-10 ans") 
        print(f"   ğŸ¯ Optimise configuration automatiquement")
        print(f"   ğŸ’¾ Sauvegarde agent super-intelligent")
        print(f"   â±ï¸ DurÃ©e: 10-15 minutes")
        
        # Option 4: Dashboard seul
        print(f"\n4ï¸âƒ£ DASHBOARD SEUL (Interface graphique)")
        print(f"   ğŸ¨ Interface web moderne")
        print(f"   ğŸ“Š Graphiques temps rÃ©el")
        print(f"   ğŸ›ï¸ ContrÃ´les START/STOP manuels")
        print(f"   ğŸŒ http://localhost:8050")
    
    def get_user_choice(self):
        """Obtenir le choix de l'utilisateur"""
        
        while True:
            try:
                print(f"\nğŸ¯ VOTRE CHOIX :")
                
                if self.has_trained_agent:
                    print(f"   ğŸ’¡ RECOMMANDÃ‰: Option 2 (Agent Trained) pour performance max")
                else:
                    print(f"   ğŸ’¡ RECOMMANDÃ‰: Option 3 (EntraÃ®ner) puis Option 2")
                
                choice = input(f"\nâ¡ï¸ Entrez votre choix [1-4]: ").strip()
                
                if choice in ['1', '2', '3', '4']:
                    return int(choice)
                else:
                    print(f"âŒ Choix invalide. Entrez 1, 2, 3 ou 4.")
                    
            except KeyboardInterrupt:
                print(f"\nğŸ‘‹ Au revoir !")
                sys.exit(0)
    
    def launch_option_1(self):
        """Lancer Agent Optimized Standard"""
        
        print(f"\nğŸš€ Lancement Agent OPTIMIZED Standard...")
        print(f"   âš¡ Puissance maximale + Intelligence anti-overtrading")
        
        try:
            from AGENT_OPTIMIZED_MAXIMUM_POWER import main as launch_optimized
            launch_optimized()
            
        except Exception as e:
            logger.error(f"âŒ Erreur lancement agent standard: {e}")
    
    def launch_option_2(self):
        """Lancer Agent Trained (si disponible)"""
        
        if not self.has_trained_agent:
            print(f"âŒ Agent entraÃ®nÃ© non disponible")
            print(f"ğŸ’¡ Choisissez option 3 pour entraÃ®ner d'abord")
            return
        
        print(f"\nğŸ“ Lancement Agent TRAINED (Historiquement Intelligent)...")
        print(f"   ğŸ“Š Patterns: {self.training_info.get('patterns_found', 0)} stratÃ©gies")
        print(f"   ğŸ§  OptimisÃ© sur {self.training_info.get('data_periods', {}).get('crypto_years', 5)} ans de donnÃ©es")
        
        try:
            from HISTORICAL_DATA_TRAINER import HistoricalDataTrainer
            
            trainer = HistoricalDataTrainer()
            trained_agent = trainer.load_trained_agent()
            
            if trained_agent:
                # Lancer session avec agent entraÃ®nÃ©
                symbols = ["BTC", "ETH", "AAPL", "TSLA", "MSFT", "GOOGL", "BNB"]
                results = trained_agent.run_optimized_session(symbols, duration_minutes=15)
                
                print(f"\nğŸ† RÃ‰SULTATS AGENT ENTRAÃNÃ‰:")
                print(f"   ğŸ“Š Performance: {results.get('return_percent', 0):.1f}%")
                print(f"   ğŸ¯ Success rate: {results.get('success_rate', 0):.1f}%")
                print(f"   ğŸ“ˆ Trades: {results.get('trades_executed', 0)}")
                
            else:
                print(f"âŒ Impossible de charger l'agent entraÃ®nÃ©")
                
        except Exception as e:
            logger.error(f"âŒ Erreur lancement agent entraÃ®nÃ©: {e}")
            import traceback
            traceback.print_exc()
    
    def launch_option_3(self):
        """EntraÃ®ner nouveau agent"""
        
        print(f"\nğŸ“ Lancement ENTRAÃNEMENT Agent...")
        print(f"   ğŸ“š Cela va prendre 10-15 minutes")
        print(f"   ğŸ“Š Collecte BTC (5-10 ans), ETH, TSLA, AAPL...")
        
        try:
            from HISTORICAL_DATA_TRAINER import main as launch_training
            launch_training()
            
            # AprÃ¨s entraÃ®nement, relancer launcher
            self.check_trained_models()
            
            if self.has_trained_agent:
                print(f"\nğŸ‰ ENTRAÃNEMENT TERMINÃ‰ !")
                print(f"   ğŸ’¡ Vous pouvez maintenant choisir Option 2")
                
                retry = input(f"\nğŸš€ Lancer directement l'agent entraÃ®nÃ© ? [y/N]: ").lower()
                if retry == 'y':
                    self.launch_option_2()
            
        except Exception as e:
            logger.error(f"âŒ Erreur entraÃ®nement: {e}")
            import traceback
            traceback.print_exc()
    
    def launch_option_4(self):
        """Lancer Dashboard seul"""
        
        print(f"\nğŸ¨ Lancement DASHBOARD Interface...")
        print(f"   ğŸŒ URL: http://localhost:8050")
        print(f"   ğŸ›ï¸ ContrÃ´les manuels dans l'interface")
        
        try:
            from AGENT_TRADING_DASHBOARD import main as launch_dashboard
            launch_dashboard()
            
        except Exception as e:
            logger.error(f"âŒ Erreur lancement dashboard: {e}")
    
    def run(self):
        """ExÃ©cuter le launcher principal"""
        
        while True:
            self.display_options()
            choice = self.get_user_choice()
            
            if choice == 1:
                self.launch_option_1()
            elif choice == 2:
                self.launch_option_2()
            elif choice == 3:
                self.launch_option_3()
            elif choice == 4:
                self.launch_option_4()
            
            # Demander si continuer
            print(f"\n" + "="*50)
            continue_choice = input(f"ğŸ”„ Revenir au menu principal ? [y/N]: ").lower()
            if continue_choice != 'y':
                break
        
        print(f"\nğŸ‘‹ Merci d'avoir utilisÃ© Smart Agent Launcher !")

def main():
    """Fonction principale"""
    
    launcher = SmartAgentLauncher()
    launcher.run()

if __name__ == "__main__":
    main()
